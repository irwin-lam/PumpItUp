{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This dataset is about the Water Wells in Tanzania. This data will need to be prepared and cleaned as it will be used in a classifer to predict the condition of a water well. \n",
    "\n",
    "<span style = 'color:green; font-size:13pt'>**Note:**</span> Clicking on anything in the table of content will send you to section. Clicking on the headers will send you back to the Table of Contents\n",
    "<hr style=\"border:2px solid magenta\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents: <a id =\"title\"><a>\n",
    "- [Imports](#imports)\n",
    "- [Opening Data](#opening)\n",
    "- [Class Explanation](#class)\n",
    "- [Pipeline Preparation](#pipeline)\n",
    "- [Dummy Model](#dummy)\n",
    "- [Baseline Model - Logistic Regression](#lg)\n",
    "- [Grid Search- Logistic Regression](#gs)\n",
    "- [SMOTE + Best Logistic Regression](#smote)\n",
    "- [Grid Search - SMOTE using Best Logistic Regression](#gs2)\n",
    "- [Summary](#summary)\n",
    "- [Exporting to CSVs](#exports)\n",
    "- [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Imports](#title) <a id =\"imports\"><a>\n",
    "<hr style=\"border:2px solid magenta\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import sklearn \n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold,cross_validate, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, LabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay, confusion_matrix, classification_report, \\\n",
    "plot_confusion_matrix, roc_curve, auc, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Opening Data](#title)  <a id ='opening'></a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "\n",
    "Creating two different models. df has more columns than df2. Opening csvs that were created from [EDA](https://github.com/irwin-lam/PumpItUp/blob/main/EDA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/TrainCleaned1.csv')\n",
    "df2 = pd.read_csv('./Data/TrainCleaned2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating x and y from each df as variables that we can use throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('status_group', axis =1)\n",
    "y = df.status_group\n",
    "\n",
    "x2 = df2.drop('status_group', axis =1)\n",
    "y2 = df2.status_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class Creation](#title)  <a id ='class'></a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "\n",
    "This class is called ModelsList  \n",
    "**functions**  \n",
    ">[<span style = 'color:green; font-size:13pt'>__ init __</span>](#func1)  \n",
    "[<span style = 'color:green; font-size:13pt'>\n",
    "    update\n",
    "    <span style = 'color:red; font-size:13pt'>\n",
    "    </span>\n",
    "</span>](#func2)  \n",
    "[<span style = 'color:green; font-size:13pt'>\n",
    "    class_report\n",
    "    <span style = 'color:red; font-size:13pt'>\n",
    "    </span>\n",
    "</span>](#func3)  \n",
    "[<span style = 'color:green; font-size:13pt'>cv_summary<span style = 'color:red; font-size:13pt'></span></span>](#func4)  \n",
    "[<span style = 'color:green; font-size:13pt'>delete_last<span style = 'color:red; font-size:13pt'></span></span>](#func5)  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**attributes**\n",
    "><span style = 'color:blue'>xtrain</span>  &rarr; x training array  \n",
    "<span style = 'color:blue'>xtest</span>  &rarr; x testing array  \n",
    "<span style = 'color:blue'>ytrain</span>  &rarr; y training array  \n",
    "<span style = 'color:blue'>ytest</span>  &rarr; y testing array  \n",
    "<span style = 'color:blue'>length</span>  &rarr; number of models' information stored  \n",
    "<span style = 'color:blue'>classification_reports</span>  &rarr;  an array of classification report  \n",
    "<span style = 'color:blue'>cv</span>  &rarr;  an array of tuples with means and std  \n",
    "<span style = 'color:blue'>df</span>  &rarr; master df that stores most of the data\n",
    "***\n",
    "**returns** Object ModelsList\n",
    "<hr style=\"border:2px solid orange\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:green; font-size:13pt'>__ init __</span><a id = 'func1'></a>  \n",
    "**parameters**  \n",
    "><span style = 'color:blue'>self</span> &rarr; refers to the object  \n",
    "<span style = 'color:blue'>x</span> &rarr; dataframe of values  \n",
    "<span style = 'color:blue'>y</span> &rarr; dataframe of targets  \n",
    "***\n",
    "**returns** Object ModelsList  \n",
    "***\n",
    "**how it works**  \n",
    "* performs a train_test_split of x and y and stores the outputs to the attributes xtrain, xtest, ytrain, ytest\n",
    "* attribute length set to 0\n",
    "* attributes classification_reports and cv set to an empty list\n",
    "* attribute df set to an empty dataframe with columns made   \n",
    "  **option to add more metrics inside**\n",
    "  \n",
    "<hr style=\"border:2px solid orange\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:green; font-size:13pt'>update</span><a id = 'func2'></a>  \n",
    "**parameters**  \n",
    "><span style = 'color:blue'>self</span> &rarr; refers to the object  \n",
    "<span style = 'color:blue'>estimator</span> &rarr; model   \n",
    "<span style = 'color:blue'>name</span> &rarr; name of the model  \n",
    "<span style = 'color:blue'>fit</span> &rarr; boolean value to see if the model needs to be fit.  \n",
    "&emsp;&emsp; DEFAULT: True   \n",
    "<span style = 'color:blue'>params</span> &rarr; a string dictionary of the hyperparameters    \n",
    "***\n",
    "**returns** Object ModelsList, prints out df  \n",
    "***\n",
    "**how it works**  \n",
    "* increase length by 1\n",
    "* if fit is set to True, fit the model with the attributes xtrain and ytrain\n",
    "* creates array ypred of the predictions of the model for xtest\n",
    "* variable log_loss is created from negative mean of cross_val_score with scoring of 'neg_log_loss' \n",
    "* variable trainscore is the score of the model for xtrain and ytrain  \n",
    "* variable testscore is the score of the model for xtest and ytest  \n",
    "* variable model_to_add is a row of the data to be inserted into the df\n",
    "  **if df has more columns, add the corresponding variable to the correct column\n",
    "  \n",
    "* adds model_to_add to df\n",
    "* variable cv is a list of accuracy scores of the train set\n",
    "* append a tuple of average and standard deviation of the scores into cv\n",
    "  \n",
    "<hr style=\"border:2px solid orange\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:green; font-size:13pt'>class_report</span><a id = 'func3'></a>  \n",
    "**parameters**  \n",
    "><span style = 'color:blue'>self</span> &rarr; refers to the object   \n",
    "***\n",
    "**returns** print classification reports  \n",
    "***\n",
    "**how it works**  \n",
    "* for loops the length \n",
    "* prints the df[Model] and classification_reports for the corresponding loop   \n",
    "\n",
    "<hr style=\"border:2px solid orange\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:green; font-size:13pt'>cv_summary</span><a id = 'func4'></a>  \n",
    "**parameters**  \n",
    "><span style = 'color:blue'>self</span> &rarr; refers to the object\n",
    "***\n",
    "**returns** print cv summaries  \n",
    "***\n",
    "**how it works**  \n",
    "* for loops the length \n",
    "* prints the df[Model] and cv which is the average and std of the scores\n",
    "\n",
    "<hr style=\"border:2px solid orange\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:green; font-size:13pt'>delete_last</span><a id = 'func5'></a>  \n",
    "**parameters**  \n",
    "><span style = 'color:blue'>self</span> &rarr; refers to the object\n",
    "***\n",
    "**returns** Object ModelsList  \n",
    "***\n",
    "**how it works**  \n",
    "* deletes the last row of the df\n",
    "* updates the length\n",
    "\n",
    "<hr style=\"border:2px solid orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelsList():\n",
    "    def __init__(self, x,y):\n",
    "        self.xtrain, self.xtest, self.ytrain, self.ytest = train_test_split(x,y,random_state=42)\n",
    "        self.length = 0\n",
    "        self.classification_reports = []\n",
    "        self.cv = []\n",
    "        self.df = pd.DataFrame({'Model' : pd.Series(dtype='str'), \n",
    "                    'train_score' : pd.Series(dtype='float64'), \n",
    "                    'test_score': pd.Series(dtype='float64'),\n",
    "                    'log_loss': pd.Series(dtype='float64'),\n",
    "                    'params':pd.Series(dtype='O')})\n",
    "    \n",
    "    def update(self, estimator, name, fit = True, params = 'None'):\n",
    "        self.length += 1\n",
    "        if fit:\n",
    "            estimator.fit(self.xtrain, self.ytrain)\n",
    "            \n",
    "        ypred = estimator.predict(self.xtest)\n",
    "        log_loss = -cross_val_score(estimator, self.xtrain, self.ytrain, scoring = 'neg_log_loss', n_jobs = -1).mean()\n",
    "        self.classification_reports.append(classification_report(self.ytest, ypred))\n",
    "        trainscore = estimator.score(self.xtrain, self.ytrain)\n",
    "        testscore = estimator.score(self.xtest, self.ytest)\n",
    "        model_to_add = [name, trainscore, testscore, log_loss, params]\n",
    "        self.df.loc[len(self.df.index)] = model_to_add\n",
    "        \n",
    "        cv = cross_val_score(estimator, self.xtrain, self.ytrain)\n",
    "        self.cv.append((cv.mean(), cv.std()))\n",
    "        return self.df\n",
    "    \n",
    "    def class_report(self):\n",
    "        for length in range(self.length):\n",
    "            print(\n",
    "            f\"\"\"Classification Report for '{self.df.Model[length]}':\n",
    "                \n",
    "            \"\"\"\n",
    "            )\n",
    "            print(self.classification_reports[length])\n",
    "            \n",
    "    def cv_summary(self):\n",
    "        for length in range(self.length):\n",
    "            print(\n",
    "            f\"\"\"Classification Report for '{self.df.Model[length]}':\n",
    "                {self.cv[length][0]:.5f} Â± {self.cv[length][1]:.5f} accuracy\n",
    "            \"\"\"\n",
    "            )\n",
    "            \n",
    "    def delete_last(self):\n",
    "        self.length -= 1\n",
    "        self.df.drop(self.df.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two ModelsList objects to store my information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ModelsList(x,y)\n",
    "model2 = ModelsList(x2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pipeline Preparation](#title) <a id ='pipeline'></a>  \n",
    "<hr style=\"border:2px solid magenta\">  \n",
    "\n",
    "Setting up two sub-pipelines to deal with numeric and categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpipenum = Pipeline([\n",
    "    ('num_impute',SimpleImputer(add_indicator=True)),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "subpipecat = Pipeline([\n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "    ('ohe', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a column transformer to utlize the sub-pipelines  \n",
    ">NOTE: using <span style = 'color:blue'>**remainder = 'passthrough'**</span> is for values that were not specified in transformers will get automatically passed through and <span style = 'color:blue'>**n_jobs = -1**</span> is for amount of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num',subpipenum, selector(dtype_include=np.number)),\n",
    "    ('subpipe_cat', subpipecat, selector(dtype_include=object))\n",
    "], remainder='passthrough', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dummy Model](#title)<a id =\"dummy\"><a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "    \n",
    "Creating a dummy model as a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('dummy', DummyClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.12076</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  train_score  test_score  log_loss params\n",
       "0  Dummy     0.447385    0.437306  19.12076   None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 30s\n",
    "model1.update(dummy, 'Dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 30 seconds and the accuracy for train and test roughly 44% with a log loss of 19.04, which is very high. Expected for a dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  train_score  test_score   log_loss params\n",
       "0  Dummy     0.447003    0.449158  19.057962   None"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 20s\n",
    "model2.update(dummy, 'Dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 20 seconds and the accuracy for train and test roughly 44% with a log loss of 19.07, which is very high. Expected for a dummy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Logistic Regression Model](#title) <a id =\"lg\"><a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "\n",
    "Lets do a basic Logistic Regression Model to see if it improves the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr1 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('lg', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr2 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('lg', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.120760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.775286</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  train_score  test_score   log_loss params\n",
       "0   Dummy     0.447385    0.437306  19.120760   None\n",
       "1  LogReg     0.861347    0.775286   0.570089   None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 50s\n",
    "model1.update(lgr1, 'LogReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took about 1 min. \n",
    "> * Training score 86.1%, testing score 77.5%, log loss 0.57. \n",
    "> * Delta between the two scores 8.6%\n",
    "> * This is a huge improvement from the dummy model. \n",
    "> * However, I cannot tell if this is good or not without playing around with the hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  train_score  test_score   log_loss params\n",
       "0   Dummy     0.447003    0.449158  19.057962   None\n",
       "1  LogReg     0.802716    0.739057   0.627404   None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 50s\n",
    "model2.update(lgr2, 'LogReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took about 30 seconds. \n",
    "> * Training score 80.9%, testing score 73.9%, a log loss 0.62. \n",
    "> * Delta between the two scores 6.4%\n",
    "> * This is a huge improvement from the dummy model. \n",
    "> * However, I cannot tell if this is good or not without playing around with the hyper parameters.\n",
    "\n",
    "<hr style=\"border:2px solid orange\">  \n",
    "\n",
    "Looking at the name of the hyper parameters that I can change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['memory', 'steps', 'verbose', 'ct', 'lg', 'ct__n_jobs', 'ct__remainder',\n",
       "       'ct__sparse_threshold', 'ct__transformer_weights', 'ct__transformers',\n",
       "       'ct__verbose', 'ct__subpipe_num', 'ct__subpipe_cat',\n",
       "       'ct__subpipe_num__memory', 'ct__subpipe_num__steps',\n",
       "       'ct__subpipe_num__verbose', 'ct__subpipe_num__num_impute',\n",
       "       'ct__subpipe_num__ss', 'ct__subpipe_num__num_impute__add_indicator',\n",
       "       'ct__subpipe_num__num_impute__copy',\n",
       "       'ct__subpipe_num__num_impute__fill_value',\n",
       "       'ct__subpipe_num__num_impute__missing_values',\n",
       "       'ct__subpipe_num__num_impute__strategy',\n",
       "       'ct__subpipe_num__num_impute__verbose', 'ct__subpipe_num__ss__copy',\n",
       "       'ct__subpipe_num__ss__with_mean', 'ct__subpipe_num__ss__with_std',\n",
       "       'ct__subpipe_cat__memory', 'ct__subpipe_cat__steps',\n",
       "       'ct__subpipe_cat__verbose', 'ct__subpipe_cat__cat_impute',\n",
       "       'ct__subpipe_cat__ohe', 'ct__subpipe_cat__cat_impute__add_indicator',\n",
       "       'ct__subpipe_cat__cat_impute__copy',\n",
       "       'ct__subpipe_cat__cat_impute__fill_value',\n",
       "       'ct__subpipe_cat__cat_impute__missing_values',\n",
       "       'ct__subpipe_cat__cat_impute__strategy',\n",
       "       'ct__subpipe_cat__cat_impute__verbose',\n",
       "       'ct__subpipe_cat__ohe__categories', 'ct__subpipe_cat__ohe__drop',\n",
       "       'ct__subpipe_cat__ohe__dtype', 'ct__subpipe_cat__ohe__handle_unknown',\n",
       "       'ct__subpipe_cat__ohe__sparse', 'lg__C', 'lg__class_weight', 'lg__dual',\n",
       "       'lg__fit_intercept', 'lg__intercept_scaling', 'lg__l1_ratio',\n",
       "       'lg__max_iter', 'lg__multi_class', 'lg__n_jobs', 'lg__penalty',\n",
       "       'lg__random_state', 'lg__solver', 'lg__tol', 'lg__verbose',\n",
       "       'lg__warm_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(lgr1.get_params(), orient='index').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lg__solver' : ['lbfgs','newton-cg', 'saga'],\n",
    "    'lg__max_iter': [250, 750, 1000, 1500],\n",
    "    'lg__C' : [0.1,0.5, 1],\n",
    "    'lg__tol' : [0.0001, 0.005, 0.001,0.01, 0.1],\n",
    "    'lg__class_weight' : [{'functional': 1, 'non functional': 1, 'functional needs repair': 2},\n",
    "                          {'functional': 1, 'non functional': 1, 'functional needs repair': 1},\n",
    "                          {'functional': 1, 'non functional': 1, 'functional needs repair': .8}]\n",
    "}\n",
    "#540 candidates x 5 folds = 2700 fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to change the hyperparameters for:\n",
    ">* lg_solver\n",
    ">* lg_max_iter\n",
    ">* lg_C\n",
    ">* lg_tol\n",
    ">* lg_class_weight\n",
    "\n",
    "I did some playing with values for this. This is what I ended up keeping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Grid Search - Logistic Regression Model](#title) <a id =\"gs\"><a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "    \n",
    "Creating GridSearchCV with the hyper parameters set above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(\n",
    "    estimator= lgr1,\n",
    "    param_grid= params,\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(\n",
    "    estimator= lgr2,\n",
    "    param_grid= params,\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting these Grid Searches.  \n",
    "**Note: These take very long to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 89.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 94.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 35min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D00>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "             param_grid={'lg__C': [0.1, 0.5, 1],\n",
       "                         'lg__class_weight': [{'functional': 1,\n",
       "                                               'functional needs repair': 2,\n",
       "                                               'non functional': 1},\n",
       "                                              {'functional': 1,\n",
       "                                               'functional needs repair': 1,\n",
       "                                               'non functional': 1},\n",
       "                                              {'functional': 1,\n",
       "                                               'functional needs repair': 0.8,\n",
       "                                               'non functional': 1}],\n",
       "                         'lg__max_iter': [250, 750, 1000, 1500],\n",
       "                         'lg__solver': ['lbfgs', 'newton-cg', 'saga'],\n",
       "                         'lg__tol': [0.0001, 0.005, 0.001, 0.01, 0.1]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#1h 36min 54s\n",
    "gs1.fit(model1.xtrain, model1.ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 55.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D00>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "             param_grid={'lg__C': [0.1, 0.5, 1],\n",
       "                         'lg__class_weight': [{'functional': 1,\n",
       "                                               'functional needs repair': 2,\n",
       "                                               'non functional': 1},\n",
       "                                              {'functional': 1,\n",
       "                                               'functional needs repair': 1,\n",
       "                                               'non functional': 1},\n",
       "                                              {'functional': 1,\n",
       "                                               'functional needs repair': 0.8,\n",
       "                                               'non functional': 1}],\n",
       "                         'lg__max_iter': [250, 750, 1000, 1500],\n",
       "                         'lg__solver': ['lbfgs', 'newton-cg', 'saga'],\n",
       "                         'lg__tol': [0.0001, 0.005, 0.001, 0.01, 0.1]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#1h 4min 20s\n",
    "gs2.fit(model2.xtrain, model2.ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took about a couple of hours to do this\n",
    "\n",
    "<hr style=\"border:2px solid orange\">\n",
    "\n",
    "Making variables to store the best_estimator and best_params.  \n",
    "Taking a quick look at the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lg__C': 0.5,\n",
       " 'lg__class_weight': {'functional': 1,\n",
       "  'non functional': 1,\n",
       "  'functional needs repair': 1},\n",
       " 'lg__max_iter': 750,\n",
       " 'lg__solver': 'lbfgs',\n",
       " 'lg__tol': 0.0001}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1best = gs1.best_estimator_\n",
    "gs1bestparam = gs1.best_params_\n",
    "gs1bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lg__C': 1,\n",
       " 'lg__class_weight': {'functional': 1,\n",
       "  'non functional': 1,\n",
       "  'functional needs repair': 0.8},\n",
       " 'lg__max_iter': 250,\n",
       " 'lg__solver': 'lbfgs',\n",
       " 'lg__tol': 0.0001}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2best = gs2.best_estimator_\n",
    "gs2bestparam = gs2.best_params_\n",
    "gs2bestparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I noticed is that C (value of 1), tolerance (value of 0.0001) and the solver (lbfgs) are the same.  \n",
    "The class weights and max_iters are different which is very interesting to see. \n",
    "\n",
    "<hr style=\"border:2px solid orange\">\n",
    "\n",
    "Using ModelsList class to update and store this model's performance/ hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.120760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.775286</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.547148</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  train_score  test_score   log_loss  \\\n",
       "0        Dummy     0.447385    0.437306  19.120760   \n",
       "1       LogReg     0.861347    0.775286   0.570089   \n",
       "2  Best LogReg     0.877800    0.781818   0.547148   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#1min 38s\n",
    "model1.update(gs1best, 'Best LogReg', False, gs1bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 2 mins. \n",
    "> * Train score 87.8%, test score 78.1%, log loss 0.547. \n",
    "> * Train score increased by 1.6%, test score increased by .6%, log loss decreased by 0.023. \n",
    "> * Delta between two scores 9.6% \n",
    "> * log loss got decreased which means it might imply its a better fitting model.  \n",
    "> * However the difference of the scores is larger, so it means it might be slightly overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>0.745859</td>\n",
       "      <td>0.617268</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  train_score  test_score   log_loss  \\\n",
       "0        Dummy     0.447003    0.449158  19.057962   \n",
       "1       LogReg     0.802716    0.739057   0.627404   \n",
       "2  Best LogReg     0.834613    0.745859   0.617268   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 1, 'lg__class_weight': {'functional'...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 1m\n",
    "model2.update(gs2best, 'Best LogReg', False, gs2bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 1 min. \n",
    "> * The train score 81.5% and test score 74.6% and log loss is 0.614. \n",
    "> * The train score increase by .6,  and the log loss also decreased about .01. \n",
    "> * This means that the model is improving. \n",
    "> * The train score improved more than the testing score, so it means that the difference got bigger. \n",
    "> * The log loss got decreased which means it might imply its a better fitting model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Smote +  Best Logistic Regression Model](#title) <a id =\"smote\"><a>\n",
    "<hr style=\"border:2px solid magenta\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Pipeline for SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbpipe1 = ImPipeline([\n",
    "    ('ct', ct),\n",
    "    ('sm', SMOTE(random_state = 42, n_jobs =-1)),\n",
    "    ('gs_best', LogisticRegression(random_state = 42, \n",
    "                                   C = gs1bestparam['lg__C'], \n",
    "                                   max_iter = gs1bestparam['lg__max_iter'], \n",
    "                                   solver = gs1bestparam['lg__solver'],\n",
    "                                   tol = gs1bestparam['lg__tol'],\n",
    "                                   class_weight = gs1bestparam['lg__class_weight'],\n",
    "                                   n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbpipe2 = ImPipeline([\n",
    "    ('ct', ct),\n",
    "    ('sm', SMOTE(random_state = 42, n_jobs =-1)),\n",
    "    ('gs_best', LogisticRegression(random_state = 42, \n",
    "                                   C = gs2bestparam['lg__C'], \n",
    "                                   max_iter = gs2bestparam['lg__max_iter'], \n",
    "                                   solver = gs2bestparam['lg__solver'],\n",
    "                                   tol = gs2bestparam['lg__tol'],\n",
    "                                   class_weight = gs2bestparam['lg__class_weight'],\n",
    "                                   n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating model1 and model2 modelslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.120760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.775286</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.547148</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.889630</td>\n",
       "      <td>0.752929</td>\n",
       "      <td>0.595275</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447385    0.437306  19.120760   \n",
       "1                  LogReg     0.861347    0.775286   0.570089   \n",
       "2             Best LogReg     0.877800    0.781818   0.547148   \n",
       "3  Smote with Best LogReg     0.889630    0.752929   0.595275   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  \n",
       "3  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#4min 4s\n",
    "model1.update(imbpipe1, 'Smote with Best LogReg', True, gs1bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took ~4 mins. \n",
    ">* Train score 89%, test score 75.2%, log loss 0.595.   \n",
    ">* Train score increase by 1.2%, test score decreased by 2.9%, the log loss increased by 0.048.  \n",
    ">* Delta between two scores 13.7%. That's pretty big   \n",
    ">* Log loss increased and delta is bigger which means it implies that it is overfit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>0.745859</td>\n",
       "      <td>0.617268</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.826308</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.680222</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447003    0.449158  19.057962   \n",
       "1                  LogReg     0.802716    0.739057   0.627404   \n",
       "2             Best LogReg     0.834613    0.745859   0.617268   \n",
       "3  Smote with Best LogReg     0.826308    0.711785   0.680222   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 1, 'lg__class_weight': {'functional'...  \n",
       "3  {'lg__C': 1, 'lg__class_weight': {'functional'...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#2min 55s\n",
    "model2.update(imbpipe2, 'Smote with Best LogReg', True, gs2bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took ~2 mins. \n",
    ">* Train score 82.6%, test score 71.1%, log loss 0.68.   \n",
    ">* Train score increase by 2.4%, test score decreased by 2.7%, the log loss increased by 0.052.  \n",
    ">* Delta between two scores 11.5%. That's pretty big   \n",
    ">* Log loss increased and delta is bigger which means it implies that it is overfit.   \n",
    "\n",
    "<hr style=\"border:2px solid orange\">\n",
    "\n",
    "Looking at the hyperparameters for SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['memory', 'steps', 'verbose', 'ct', 'sm', 'gs_best', 'ct__n_jobs',\n",
       "       'ct__remainder', 'ct__sparse_threshold', 'ct__transformer_weights',\n",
       "       'ct__transformers', 'ct__verbose', 'ct__subpipe_num', 'ct__subpipe_cat',\n",
       "       'ct__subpipe_num__memory', 'ct__subpipe_num__steps',\n",
       "       'ct__subpipe_num__verbose', 'ct__subpipe_num__num_impute',\n",
       "       'ct__subpipe_num__ss', 'ct__subpipe_num__num_impute__add_indicator',\n",
       "       'ct__subpipe_num__num_impute__copy',\n",
       "       'ct__subpipe_num__num_impute__fill_value',\n",
       "       'ct__subpipe_num__num_impute__missing_values',\n",
       "       'ct__subpipe_num__num_impute__strategy',\n",
       "       'ct__subpipe_num__num_impute__verbose', 'ct__subpipe_num__ss__copy',\n",
       "       'ct__subpipe_num__ss__with_mean', 'ct__subpipe_num__ss__with_std',\n",
       "       'ct__subpipe_cat__memory', 'ct__subpipe_cat__steps',\n",
       "       'ct__subpipe_cat__verbose', 'ct__subpipe_cat__cat_impute',\n",
       "       'ct__subpipe_cat__ohe', 'ct__subpipe_cat__cat_impute__add_indicator',\n",
       "       'ct__subpipe_cat__cat_impute__copy',\n",
       "       'ct__subpipe_cat__cat_impute__fill_value',\n",
       "       'ct__subpipe_cat__cat_impute__missing_values',\n",
       "       'ct__subpipe_cat__cat_impute__strategy',\n",
       "       'ct__subpipe_cat__cat_impute__verbose',\n",
       "       'ct__subpipe_cat__ohe__categories', 'ct__subpipe_cat__ohe__drop',\n",
       "       'ct__subpipe_cat__ohe__dtype', 'ct__subpipe_cat__ohe__handle_unknown',\n",
       "       'ct__subpipe_cat__ohe__sparse', 'sm__k_neighbors', 'sm__n_jobs',\n",
       "       'sm__random_state', 'sm__sampling_strategy', 'gs_best__C',\n",
       "       'gs_best__class_weight', 'gs_best__dual', 'gs_best__fit_intercept',\n",
       "       'gs_best__intercept_scaling', 'gs_best__l1_ratio', 'gs_best__max_iter',\n",
       "       'gs_best__multi_class', 'gs_best__n_jobs', 'gs_best__penalty',\n",
       "       'gs_best__random_state', 'gs_best__solver', 'gs_best__tol',\n",
       "       'gs_best__verbose', 'gs_best__warm_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(imbpipe1.get_params(), orient='index').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sm__sampling_strategy' : ['minority', 'not majority', 'all'],\n",
    "    'sm__k_neighbors': [5,10,15]\n",
    "}\n",
    "#9 candidiates x 5 folds = 45 fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Grid Search - Smote Using Best Logistic Regression Model](#title) <a id =\"gs2\"><a>\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "    \n",
    "Setting up Grid Searches with the hyper parameters given above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gs1 = GridSearchCV(\n",
    "    estimator= imbpipe1,\n",
    "    param_grid= params,\n",
    "    cv =5,\n",
    "    verbose = 2,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gs2 = GridSearchCV(\n",
    "    estimator= imbpipe2,\n",
    "    param_grid= params,\n",
    "    cv =5,\n",
    "    verbose = 2,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D00>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D30>)])),\n",
       "                                       ('sm',\n",
       "                                        SMOTE(n_jobs=-1, random_state=42)),\n",
       "                                       ('gs_best',\n",
       "                                        LogisticRegression(C=0.5,\n",
       "                                                           class_weight={'functional': 1,\n",
       "                                                                         'functional needs repair': 1,\n",
       "                                                                         'non functional': 1},\n",
       "                                                           max_iter=750,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'sm__k_neighbors': [5, 10, 15],\n",
       "                         'sm__sampling_strategy': ['minority', 'not majority',\n",
       "                                                   'all']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#5min 52s\n",
    "smote_gs1.fit(model1.xtrain,model1.ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D00>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x000001CCE8E33D30>)])),\n",
       "                                       ('sm',\n",
       "                                        SMOTE(n_jobs=-1, random_state=42)),\n",
       "                                       ('gs_best',\n",
       "                                        LogisticRegression(C=1,\n",
       "                                                           class_weight={'functional': 1,\n",
       "                                                                         'functional needs repair': 0.8,\n",
       "                                                                         'non functional': 1},\n",
       "                                                           max_iter=250,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'sm__k_neighbors': [5, 10, 15],\n",
       "                         'sm__sampling_strategy': ['minority', 'not majority',\n",
       "                                                   'all']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#3min 29s\n",
    "smote_gs2.fit(model2.xtrain,model2.ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a lot faster than the logistic regression grid search becuase I am only doing 45 fits compared to 2700 fits\n",
    "\n",
    "<hr style=\"border:2px solid orange\">\n",
    "\n",
    "Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gs1best = smote_gs1.best_estimator_\n",
    "smote_gs2best = smote_gs2.best_estimator_\n",
    "\n",
    "smote_gs1bestparam = smote_gs1.best_params_\n",
    "smote_gs2bestparam = smote_gs2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid orange\">\n",
    "\n",
    "Updating model1 and model2 ModelsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.120760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.775286</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.547148</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.889630</td>\n",
       "      <td>0.752929</td>\n",
       "      <td>0.595275</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Smote + LogReg</td>\n",
       "      <td>0.879596</td>\n",
       "      <td>0.753266</td>\n",
       "      <td>0.596776</td>\n",
       "      <td>{'sm__k_neighbors': 15, 'sm__sampling_strategy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447385    0.437306  19.120760   \n",
       "1                  LogReg     0.861347    0.775286   0.570089   \n",
       "2             Best LogReg     0.877800    0.781818   0.547148   \n",
       "3  Smote with Best LogReg     0.889630    0.752929   0.595275   \n",
       "4     Best Smote + LogReg     0.879596    0.753266   0.596776   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  \n",
       "3  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  \n",
       "4  {'sm__k_neighbors': 15, 'sm__sampling_strategy...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# roughly 1m\n",
    "model1.update(smote_gs1best, 'Best Smote + LogReg', False, smote_gs1bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took ~4 mins. \n",
    ">* Train score 88%, test score 75.3%, log loss 0.597.   \n",
    ">* Train score increase by 1.8%, test score decreased by 2.2%, the log loss increased by .026.  \n",
    ">* Delta between two scores 12.6%. That's pretty big   \n",
    ">* Log loss increased and delta is bigger which means it implies that it is overfit.   \n",
    ">* This did slightly worse in the training than previous model and had a bigger 'error'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>0.745859</td>\n",
       "      <td>0.617268</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.826308</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.680222</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Smote + LogReg</td>\n",
       "      <td>0.826891</td>\n",
       "      <td>0.714613</td>\n",
       "      <td>0.678226</td>\n",
       "      <td>{'sm__k_neighbors': 5, 'sm__sampling_strategy'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447003    0.449158  19.057962   \n",
       "1                  LogReg     0.802716    0.739057   0.627404   \n",
       "2             Best LogReg     0.834613    0.745859   0.617268   \n",
       "3  Smote with Best LogReg     0.826308    0.711785   0.680222   \n",
       "4     Best Smote + LogReg     0.826891    0.714613   0.678226   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 1, 'lg__class_weight': {'functional'...  \n",
       "3  {'lg__C': 1, 'lg__class_weight': {'functional'...  \n",
       "4  {'sm__k_neighbors': 5, 'sm__sampling_strategy'...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# roughly 1m\n",
    "model2.update(smote_gs2best, 'Best Smote + LogReg', False, smote_gs2bestparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Summary](#title) <a id =\"summary\"><a>\n",
    "\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "    \n",
    "Showing useful values to evaluate which model is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 'Dummy':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.55      0.55      0.55      8098\n",
      "functional needs repair       0.08      0.08      0.08      1074\n",
      "         non functional       0.39      0.39      0.39      5678\n",
      "\n",
      "               accuracy                           0.45     14850\n",
      "              macro avg       0.34      0.34      0.34     14850\n",
      "           weighted avg       0.45      0.45      0.45     14850\n",
      "\n",
      "Classification Report for 'LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.87      0.82      8098\n",
      "functional needs repair       0.54      0.26      0.35      1074\n",
      "         non functional       0.80      0.74      0.77      5678\n",
      "\n",
      "               accuracy                           0.78     14850\n",
      "              macro avg       0.70      0.62      0.65     14850\n",
      "           weighted avg       0.77      0.78      0.77     14850\n",
      "\n",
      "Classification Report for 'Best LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.89      0.83      8098\n",
      "functional needs repair       0.59      0.23      0.34      1074\n",
      "         non functional       0.81      0.74      0.77      5678\n",
      "\n",
      "               accuracy                           0.78     14850\n",
      "              macro avg       0.72      0.62      0.64     14850\n",
      "           weighted avg       0.77      0.78      0.77     14850\n",
      "\n",
      "Classification Report for 'Smote with Best LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.79      0.80      8098\n",
      "functional needs repair       0.34      0.53      0.42      1074\n",
      "         non functional       0.80      0.75      0.77      5678\n",
      "\n",
      "               accuracy                           0.75     14850\n",
      "              macro avg       0.65      0.69      0.66     14850\n",
      "           weighted avg       0.77      0.75      0.76     14850\n",
      "\n",
      "Classification Report for 'Best Smote + LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.81      0.80      8098\n",
      "functional needs repair       0.34      0.55      0.42      1074\n",
      "         non functional       0.83      0.71      0.76      5678\n",
      "\n",
      "               accuracy                           0.75     14850\n",
      "              macro avg       0.65      0.69      0.66     14850\n",
      "           weighted avg       0.78      0.75      0.76     14850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.class_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 'Dummy':\n",
      "                0.44842 Â± 0.00252 accuracy\n",
      "            \n",
      "Classification Report for 'LogReg':\n",
      "                0.77336 Â± 0.00296 accuracy\n",
      "            \n",
      "Classification Report for 'Best LogReg':\n",
      "                0.77915 Â± 0.00242 accuracy\n",
      "            \n",
      "Classification Report for 'Smote with Best LogReg':\n",
      "                0.75086 Â± 0.00287 accuracy\n",
      "            \n",
      "Classification Report for 'Best Smote + LogReg':\n",
      "                0.75169 Â± 0.00356 accuracy\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "model1.cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.437306</td>\n",
       "      <td>19.120760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.775286</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.547148</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.889630</td>\n",
       "      <td>0.752929</td>\n",
       "      <td>0.595275</td>\n",
       "      <td>{'lg__C': 0.5, 'lg__class_weight': {'functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Smote + LogReg</td>\n",
       "      <td>0.879596</td>\n",
       "      <td>0.753266</td>\n",
       "      <td>0.596776</td>\n",
       "      <td>{'sm__k_neighbors': 15, 'sm__sampling_strategy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447385    0.437306  19.120760   \n",
       "1                  LogReg     0.861347    0.775286   0.570089   \n",
       "2             Best LogReg     0.877800    0.781818   0.547148   \n",
       "3  Smote with Best LogReg     0.889630    0.752929   0.595275   \n",
       "4     Best Smote + LogReg     0.879596    0.753266   0.596776   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  \n",
       "3  {'lg__C': 0.5, 'lg__class_weight': {'functiona...  \n",
       "4  {'sm__k_neighbors': 15, 'sm__sampling_strategy...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Best Logistic Regression performs the best overall. It has the highest test score and the lowest log loss. These are very good metrics to look at. Another note to look at is that it has the highest f1 score for functional.  \n",
    "- Smote models performed better at predicting the needs repair class, but it did not perform that much better than the Logistic Regression.  \n",
    "- Despite Smote models having the highest scores for train, it seems like it overfit due to the test score doing much worse. \n",
    "\n",
    "<hr style=\"border:2px solid orange\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 'Dummy':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.55      0.55      0.55      8098\n",
      "functional needs repair       0.07      0.07      0.07      1074\n",
      "         non functional       0.38      0.38      0.38      5678\n",
      "\n",
      "               accuracy                           0.45     14850\n",
      "              macro avg       0.33      0.33      0.33     14850\n",
      "           weighted avg       0.45      0.45      0.45     14850\n",
      "\n",
      "Classification Report for 'LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.75      0.84      0.79      8098\n",
      "functional needs repair       0.52      0.25      0.34      1074\n",
      "         non functional       0.74      0.69      0.71      5678\n",
      "\n",
      "               accuracy                           0.74     14850\n",
      "              macro avg       0.67      0.59      0.61     14850\n",
      "           weighted avg       0.73      0.74      0.73     14850\n",
      "\n",
      "Classification Report for 'Best LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.75      0.85      0.80      8098\n",
      "functional needs repair       0.59      0.21      0.31      1074\n",
      "         non functional       0.74      0.70      0.72      5678\n",
      "\n",
      "               accuracy                           0.75     14850\n",
      "              macro avg       0.70      0.59      0.61     14850\n",
      "           weighted avg       0.74      0.75      0.73     14850\n",
      "\n",
      "Classification Report for 'Smote with Best LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.79      0.74      0.76      8098\n",
      "functional needs repair       0.33      0.53      0.40      1074\n",
      "         non functional       0.73      0.71      0.72      5678\n",
      "\n",
      "               accuracy                           0.71     14850\n",
      "              macro avg       0.61      0.66      0.63     14850\n",
      "           weighted avg       0.73      0.71      0.72     14850\n",
      "\n",
      "Classification Report for 'Best Smote + LogReg':\n",
      "                \n",
      "            \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.78      0.77      0.77      8098\n",
      "functional needs repair       0.32      0.54      0.40      1074\n",
      "         non functional       0.76      0.67      0.71      5678\n",
      "\n",
      "               accuracy                           0.71     14850\n",
      "              macro avg       0.62      0.66      0.63     14850\n",
      "           weighted avg       0.74      0.71      0.72     14850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.class_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 'Dummy':\n",
      "                0.44716 Â± 0.00831 accuracy\n",
      "            \n",
      "Classification Report for 'LogReg':\n",
      "                0.73661 Â± 0.00495 accuracy\n",
      "            \n",
      "Classification Report for 'Best LogReg':\n",
      "                0.74083 Â± 0.00353 accuracy\n",
      "            \n",
      "Classification Report for 'Smote with Best LogReg':\n",
      "                0.70723 Â± 0.00230 accuracy\n",
      "            \n",
      "Classification Report for 'Best Smote + LogReg':\n",
      "                0.71057 Â± 0.00464 accuracy\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "model2.cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>19.057962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.802716</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best LogReg</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>0.745859</td>\n",
       "      <td>0.617268</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote with Best LogReg</td>\n",
       "      <td>0.826308</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.680222</td>\n",
       "      <td>{'lg__C': 1, 'lg__class_weight': {'functional'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Smote + LogReg</td>\n",
       "      <td>0.826891</td>\n",
       "      <td>0.714613</td>\n",
       "      <td>0.678226</td>\n",
       "      <td>{'sm__k_neighbors': 5, 'sm__sampling_strategy'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  train_score  test_score   log_loss  \\\n",
       "0                   Dummy     0.447003    0.449158  19.057962   \n",
       "1                  LogReg     0.802716    0.739057   0.627404   \n",
       "2             Best LogReg     0.834613    0.745859   0.617268   \n",
       "3  Smote with Best LogReg     0.826308    0.711785   0.680222   \n",
       "4     Best Smote + LogReg     0.826891    0.714613   0.678226   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'lg__C': 1, 'lg__class_weight': {'functional'...  \n",
       "3  {'lg__C': 1, 'lg__class_weight': {'functional'...  \n",
       "4  {'sm__k_neighbors': 5, 'sm__sampling_strategy'...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exporting to CSVs](#title) <a id =\"exports\"><a>\n",
    "\n",
    "<hr style=\"border:2px solid magenta\">\n",
    "    \n",
    "Export modellists as csvs to explore in the visualizations notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.df.to_csv('./Data/Model1.csv', index=False)\n",
    "model2.df.to_csv('./Data/Model2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the cv_results from the Grid Search to explore at a later time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1cv_results = pd.DataFrame.from_dict(gs1.cv_results_)\n",
    "gs2cv_results = pd.DataFrame.from_dict(gs2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gs1cv_results = pd.DataFrame.from_dict(smote_gs1.cv_results_)\n",
    "smote_gs2cv_results = pd.DataFrame.from_dict(smote_gs2.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting these cv_results as a csv to explore one day in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1cv_results.to_csv('./Data/GridSearch1cv_results.csv', index=False)\n",
    "gs2cv_results.to_csv('./Data/GridSearch2cv_results.csv', index=False)\n",
    "smote_gs1cv_results.to_csv('./Data/SmoteGridSearch1cv_results.csv', index=False)\n",
    "smote_gs2cv_results.to_csv('./Data/SmoteGridSearch2cv_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create some visualizations in the next [notebook](https://github.com/irwin-lam/PumpItUp/blob/main/Visualizations.ipynb). \n",
    "\n",
    "### [Conclusions](#title) <a id =\"conclusions\"><a>\n",
    "\n",
    "<hr style=\"border:2px solid magenta\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is the Logistic Regression with Tuned hyperparameters. \n",
    "> * The C is set to 0.5. \n",
    "> * The class weight is set to be balanced. \n",
    "> * The max iterations is set to 750. \n",
    "> * The solver is set to lbfgs. \n",
    "> * The tolerance is set to 0.0001. \n",
    "\n",
    "Out of the models I used, this model has the lowest log loss. The test accuracy is the highest out of the five models I did. The difference between the training score and test score is relatively low. The recall value for the functional class is the highest. We would want to avoid going to a functional water source too often. The recall value is the true positive over all positives for that class. By having a 89%, this means only 11% of the positives for functional are false positive. \n",
    "\n",
    "The next step would be to convert this problem to a binary classification as it makes more sense to send someone to repair a water source that is either not functional or needs repairs than a functional well. This would remove the uncertainity if the water source needs repair due our dataset being limited in that class. The other models might perform better in this situation as the data imbalance would be removed. There is roughly only 7% of the data is classified as needs repairs, and 38% of the data is classified as non functional. This better even out the class distribution to be 45-55. \n",
    "\n",
    "Another step would be getting data about the deaths and sicknesses in the regions from the water quality. This would provide more insight in which region to focus on sending people to repair or build new water sources.  This could add more weight to certain regions as it is more \"important\" to focus those regions as it would save more people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
