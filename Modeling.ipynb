{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay, confusion_matrix, recall_score, \\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/TrainCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('status_group', axis =1)\n",
    "y = df.status_group\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelsList():\n",
    "    def __init__(self, x,y):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x,y)\n",
    "        self.xtrain = xtrain\n",
    "        self.xtest = xtest\n",
    "        self.ytrain = ytrain\n",
    "        self.ytest = ytest\n",
    "        self.df = pd.DataFrame({'Model' : pd.Series(dtype='str'), \n",
    "                    'train_score' : pd.Series(dtype='float64'), \n",
    "                    'test_score': pd.Series(dtype='float64'),\n",
    "                    'log_loss': pd.Series(dtype='float64'),\n",
    "                    'params':pd.Series(dtype='O')})\n",
    "    \n",
    "    def update(self, estimator, name, fit = True, params = 'None'):\n",
    "        if fit:\n",
    "            estimator.fit(self.xtrain, self.ytrain)\n",
    "        \n",
    "        log_loss = -cross_val_score(estimator, self.xtrain, self.ytrain, scoring= 'neg_log_loss' ).mean()                        \n",
    "        trainscore = estimator.score(self.xtrain, self.ytrain)\n",
    "        testscore = estimator.score(self.xtest, self.ytest)\n",
    "        model_to_add = [name, trainscore, testscore, log_loss, params]\n",
    "        self.df.loc[len(self.df.index)] = model_to_add\n",
    "        return self.df\n",
    "    \n",
    "    def delete_last(self):\n",
    "        self.df.drop(self.df.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ModelsList(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpipenum = Pipeline([\n",
    "    ('num_impute',SimpleImputer(add_indicator=True)),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "subpipecat = Pipeline([\n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "    ('ohe', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num',subpipenum, selector(dtype_include=np.number)),\n",
    "    ('subpipe_cat', subpipecat, selector(dtype_include=object))\n",
    "], remainder='passthrough',n_jobs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('fsm', LogisticRegression(random_state=327, n_jobs=12))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.825567</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.564681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  train_score  test_score  log_loss params\n",
       "0  baseline     0.825567    0.776229  0.564681   None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 1m\n",
    "models_list.update(model, 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['memory', 'steps', 'verbose', 'ct', 'fsm', 'ct__n_jobs',\n",
       "       'ct__remainder', 'ct__sparse_threshold', 'ct__transformer_weights',\n",
       "       'ct__transformers', 'ct__verbose', 'ct__subpipe_num', 'ct__subpipe_cat',\n",
       "       'ct__subpipe_num__memory', 'ct__subpipe_num__steps',\n",
       "       'ct__subpipe_num__verbose', 'ct__subpipe_num__num_impute',\n",
       "       'ct__subpipe_num__ss', 'ct__subpipe_num__num_impute__add_indicator',\n",
       "       'ct__subpipe_num__num_impute__copy',\n",
       "       'ct__subpipe_num__num_impute__fill_value',\n",
       "       'ct__subpipe_num__num_impute__missing_values',\n",
       "       'ct__subpipe_num__num_impute__strategy',\n",
       "       'ct__subpipe_num__num_impute__verbose', 'ct__subpipe_num__ss__copy',\n",
       "       'ct__subpipe_num__ss__with_mean', 'ct__subpipe_num__ss__with_std',\n",
       "       'ct__subpipe_cat__memory', 'ct__subpipe_cat__steps',\n",
       "       'ct__subpipe_cat__verbose', 'ct__subpipe_cat__cat_impute',\n",
       "       'ct__subpipe_cat__ohe', 'ct__subpipe_cat__cat_impute__add_indicator',\n",
       "       'ct__subpipe_cat__cat_impute__copy',\n",
       "       'ct__subpipe_cat__cat_impute__fill_value',\n",
       "       'ct__subpipe_cat__cat_impute__missing_values',\n",
       "       'ct__subpipe_cat__cat_impute__strategy',\n",
       "       'ct__subpipe_cat__cat_impute__verbose',\n",
       "       'ct__subpipe_cat__ohe__categories', 'ct__subpipe_cat__ohe__drop',\n",
       "       'ct__subpipe_cat__ohe__dtype', 'ct__subpipe_cat__ohe__handle_unknown',\n",
       "       'ct__subpipe_cat__ohe__sparse', 'fsm__C', 'fsm__class_weight',\n",
       "       'fsm__dual', 'fsm__fit_intercept', 'fsm__intercept_scaling',\n",
       "       'fsm__l1_ratio', 'fsm__max_iter', 'fsm__multi_class', 'fsm__n_jobs',\n",
       "       'fsm__penalty', 'fsm__random_state', 'fsm__solver', 'fsm__tol',\n",
       "       'fsm__verbose', 'fsm__warm_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(model.get_params(), orient='index').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'ct__subpipe_num__num_impute__strategy' : ['mean','median'],\n",
    "    'fsm__solver' : ['liblinear','lbfgs','newton-cg', 'saga'],\n",
    "    'fsm__max_iter': [100,1000,10000],\n",
    "    'fsm__C' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'fsm__tol' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator= model,\n",
    "    param_grid= params,\n",
    "    cv =5,\n",
    "    verbose = 2,\n",
    "    n_jobs = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=12)]: Done 989 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=12)]: Done 1434 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=12)]: Done 1800 out of 1800 | elapsed: 30.0min finished\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=12,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC700>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC820>)])),\n",
       "                                       ('fsm',\n",
       "                                        LogisticRegression(n_jobs=12,\n",
       "                                                           random_state=327))]),\n",
       "             n_jobs=12,\n",
       "             param_grid={'ct__subpipe_num__num_impute__strategy': ['mean',\n",
       "                                                                   'median'],\n",
       "                         'fsm__C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'fsm__max_iter': [100, 1000, 10000],\n",
       "                         'fsm__solver': ['liblinear', 'lbfgs', 'newton-cg',\n",
       "                                         'saga'],\n",
       "                         'fsm__tol': [0.0001, 0.001, 0.01]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# ROUGHLY 33 MINS\n",
    "gs.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsbest = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.825567</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.564681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Best Grid Search</td>\n",
       "      <td>0.828732</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.547725</td>\n",
       "      <td>{'ct__subpipe_num__num_impute__strategy': 'mea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  train_score  test_score  log_loss  \\\n",
       "0                   baseline     0.825567    0.776229  0.564681   \n",
       "1  Baseline Best Grid Search     0.828732    0.824512  0.547725   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1  {'ct__subpipe_num__num_impute__strategy': 'mea...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 30s\n",
    "models_list.update(gsbest, 'Baseline Best Grid Search', False, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_list.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_indices = [1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "# sampling_strategy_dict = {'non functional':18200,\n",
    "#                           'functional needs repair':18200,\n",
    "#                           'functional': 24169\n",
    "#                          }\n",
    "# sm = SMOTENC(sampling_strategy = sampling_strategy_dict, categorical_features=categorical_indices, random_state = 327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbpipe = ImPipeline([\n",
    "    ('ct', ct),\n",
    "    ('sm', SMOTE(random_state = 327)),\n",
    "    ('gs_best', LogisticRegression(random_state = 327, C=1,max_iter=1000, solver='liblinear',tol=.0001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.825567</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.564681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Best Grid Search</td>\n",
       "      <td>0.828732</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.547725</td>\n",
       "      <td>{'ct__subpipe_num__num_impute__strategy': 'mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline Best Grid Search + Smote</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.734141</td>\n",
       "      <td>0.621575</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  train_score  test_score  log_loss  \\\n",
       "0                           baseline     0.825567    0.776229  0.564681   \n",
       "1          Baseline Best Grid Search     0.828732    0.824512  0.547725   \n",
       "2  Baseline Best Grid Search + Smote     0.834074    0.734141  0.621575   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1  {'ct__subpipe_num__num_impute__strategy': 'mea...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 1m\n",
    "models_list.update(imbpipe, 'Baseline Best Grid Search + Smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbpipe2 = ImPipeline([\n",
    "    ('ct', ct),\n",
    "    ('sm', SMOTE(random_state = 327)),\n",
    "    ('baseline', LogisticRegression(random_state = 327))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(n_jobs=12, remainder='passthrough',\n",
       "                                   transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC700>),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('cat_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC820>)])),\n",
       "                ('sm', SMOTE(random_state=327)),\n",
       "                ('baseline', LogisticRegression(random_state=327))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 20s\n",
    "imbpipe2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'ct__subpipe_num__num_impute__strategy' : ['mean','median'],\n",
    "    'baseline__solver' : ['liblinear','lbfgs','newton-cg', 'saga'],\n",
    "    'baseline__max_iter': [100,1000,10000],\n",
    "    'baseline__C' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'baseline__tol' : [0.0001, 0.001, 0.01]\n",
    "}\n",
    "gs2 = GridSearchCV(\n",
    "    estimator= imbpipe2,\n",
    "    param_grid= params,\n",
    "    cv =5,\n",
    "    verbose = 2,\n",
    "    n_jobs = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=12)]: Done 989 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=12)]: Done 1434 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=12)]: Done 1800 out of 1800 | elapsed: 79.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 19min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(n_jobs=12,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC700>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('cat_imput...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x00000210066EC820>)])),\n",
       "                                       ('sm', SMOTE(random_state=327)),\n",
       "                                       ('baseline',\n",
       "                                        LogisticRegression(random_state=327))]),\n",
       "             n_jobs=12,\n",
       "             param_grid={'baseline__C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'baseline__max_iter': [100, 1000, 10000],\n",
       "                         'baseline__solver': ['liblinear', 'lbfgs', 'newton-cg',\n",
       "                                              'saga'],\n",
       "                         'baseline__tol': [0.0001, 0.001, 0.01],\n",
       "                         'ct__subpipe_num__num_impute__strategy': ['mean',\n",
       "                                                                   'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#roughly 30m\n",
    "gs2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2best = gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.825567</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.564681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Best Grid Search</td>\n",
       "      <td>0.828732</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.547725</td>\n",
       "      <td>{'ct__subpipe_num__num_impute__strategy': 'mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline Best Grid Search + Smote</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.734141</td>\n",
       "      <td>0.621575</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote Grid Search</td>\n",
       "      <td>0.826397</td>\n",
       "      <td>0.819461</td>\n",
       "      <td>0.625927</td>\n",
       "      <td>{'baseline__C': 1, 'baseline__max_iter': 100, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  train_score  test_score  log_loss  \\\n",
       "0                           baseline     0.825567    0.776229  0.564681   \n",
       "1          Baseline Best Grid Search     0.828732    0.824512  0.547725   \n",
       "2  Baseline Best Grid Search + Smote     0.834074    0.734141  0.621575   \n",
       "3                  Smote Grid Search     0.826397    0.819461  0.625927   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1  {'ct__subpipe_num__num_impute__strategy': 'mea...  \n",
       "2                                               None  \n",
       "3  {'baseline__C': 1, 'baseline__max_iter': 100, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list.update(gs2best, 'Smote Grid Search', False, gs2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.825567</td>\n",
       "      <td>0.776229</td>\n",
       "      <td>0.564681</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Best Grid Search</td>\n",
       "      <td>0.828732</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.547725</td>\n",
       "      <td>{'ct__subpipe_num__num_impute__strategy': 'mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline Best Grid Search + Smote</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.734141</td>\n",
       "      <td>0.621575</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smote Grid Search</td>\n",
       "      <td>0.826397</td>\n",
       "      <td>0.819461</td>\n",
       "      <td>0.625927</td>\n",
       "      <td>{'baseline__C': 1, 'baseline__max_iter': 100, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  train_score  test_score  log_loss  \\\n",
       "0                           baseline     0.825567    0.776229  0.564681   \n",
       "1          Baseline Best Grid Search     0.828732    0.824512  0.547725   \n",
       "2  Baseline Best Grid Search + Smote     0.834074    0.734141  0.621575   \n",
       "3                  Smote Grid Search     0.826397    0.819461  0.625927   \n",
       "\n",
       "                                              params  \n",
       "0                                               None  \n",
       "1  {'ct__subpipe_num__num_impute__strategy': 'mea...  \n",
       "2                                               None  \n",
       "3  {'baseline__C': 1, 'baseline__max_iter': 100, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "models_list.update(gs2best, 'Smote Grid Search', False, gs2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('pca', PCA(random_state = 327)),\n",
    "    ('classifier', RandomForestClassifier(random_state=327))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PCA does not support sparse input. See TruncatedSVD for a possible alternative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c35aad80b44d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;31m# This is more informative than the generic one raised by check_array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             raise TypeError('PCA does not support sparse input. See '\n\u001b[0m\u001b[0;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: PCA does not support sparse input. See TruncatedSVD for a possible alternative."
     ]
    }
   ],
   "source": [
    "pca.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
